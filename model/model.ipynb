{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl import heterograph\n",
    "import dgl.function as fn\n",
    "import dgl.utils as dgl_utils\n",
    "from functools import partial\n",
    "from dgl.nn.pytorch import RelGraphConv\n",
    "from dgl.contrib.data import load_data\n",
    "\n",
    "import numpy as np\n",
    "import pygraphviz as pgv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import utils\n",
    "from base import BaseRGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load graph as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_dict = utils.read_dict_file('../data/clean/graph_dict.txt')\n",
    "# g = heterograph(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(nxg):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "    ag.layout('dot')\n",
    "    ag.draw('graph.png')\n",
    "    ag.edge_attr['front_size']=0.1\n",
    "\n",
    "# plot_graph(g.metagraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        # create an embedding value [0,1] for each node of the graph\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, h_dim)\n",
    "\n",
    "    def forward(self, g, h, r, norm):\n",
    "        return self.embedding(h.squeeze())\n",
    "\n",
    "class RGCN(BaseRGCN):\n",
    "    def build_input_layer(self):\n",
    "        return EmbeddingLayer(self.num_nodes, self.h_dim)\n",
    "\n",
    "    def build_hidden_layer(self, idx):\n",
    "        # build a number of hidden layer according to the parameter\n",
    "        # add a relu activation function except for the last layer\n",
    "        act = F.relu if idx < self.num_hidden_layers - 1 else None\n",
    "        return RelGraphConv(self.h_dim, self.h_dim, self.num_rels, 'basis',\n",
    "                self.num_bases, activation=act, self_loop=True,\n",
    "                dropout=self.dropout)\n",
    "\n",
    "class LinkPredict(nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, num_rels, num_bases=-1,\n",
    "                 num_hidden_layers=1, dropout=0, use_cuda=False, reg_param=0):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        - in_dim (int) -- input feature size\n",
    "        - h_dim  (int) -- output feature size\n",
    "        - num_rels (int) -- # relations\n",
    "        - num_bases (int) -- # bases\n",
    "        - num_hidden_layers (int) -- # hidden layers\n",
    "        - dropout (float) -- [0,1] dropout rate\n",
    "        - use_cuda (bool)\n",
    "        - reg_param (float) -- regularization parameter\n",
    "        \"\"\"\n",
    "        super(LinkPredict, self).__init__()\n",
    "        # build RGCN layer\n",
    "        # 2 x num_rels as both directions are considered\n",
    "        self.rgcn = RGCN(in_dim, h_dim, h_dim, num_rels * 2, num_bases,\n",
    "                         num_hidden_layers, dropout, use_cuda)\n",
    "        # define regularization\n",
    "        self.reg_param = reg_param\n",
    "        # define relations and normalize them\n",
    "        self.w_relation = nn.Parameter(torch.Tensor(num_rels, h_dim))\n",
    "        nn.init.xavier_uniform_(self.w_relation,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def calc_score(self, embedding, triplets):\n",
    "        # apply DistMult for scoring\n",
    "        # embedding contains the embedding values of the node after the \n",
    "        #   propagation within the RGCN Block layer\n",
    "        # triplets contains all triples resulting from the negative sampling process\n",
    "        s = embedding[triplets[:,0]]\n",
    "        r = self.w_relation[triplets[:,1]]\n",
    "        o = embedding[triplets[:,2]]\n",
    "        score = torch.sum(s * r * o, dim=1)\n",
    "        return score\n",
    "\n",
    "    def forward(self, g, h, r, norm):\n",
    "        return self.rgcn.forward(g, h, r, norm)\n",
    "\n",
    "    def regularization_loss(self, embedding):\n",
    "        return torch.mean(embedding.pow(2)) + torch.mean(self.w_relation.pow(2))\n",
    "\n",
    "    def get_loss(self, g, embed, triplets, labels):\n",
    "        # triplets is a list of data samples (positive and negative)\n",
    "        # each row in the triplets is a 3-tuple of (source, relation, destination)\n",
    "        \n",
    "        # The score is computed with the value-by-value multiplication of\n",
    "        #   the embedding values of data produced by the negative sampling process\n",
    "        #   and sum them using the vertical dimension\n",
    "        \n",
    "        score = self.calc_score(embed, triplets)\n",
    "        predict_loss = F.binary_cross_entropy_with_logits(score, labels)\n",
    "        reg_loss = self.regularization_loss(embed)\n",
    "        return predict_loss + self.reg_param * reg_loss\n",
    "\n",
    "def node_norm_to_edge_norm(g, node_norm):\n",
    "    g = g.local_var()\n",
    "    # convert to edge norm\n",
    "    g.ndata['norm'] = node_norm\n",
    "    g.apply_edges(lambda edges : {'norm' : edges.dst['norm']})\n",
    "    return g.edata['norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = np.load('../data/clean/graph.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(list(set(np.unique(graph[:,0])).union(set(np.unique(graph[:,2])))))\n",
    "num_rels = np.unique(graph[:,1]).shape[0]\n",
    "num_edges = graph.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212123, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test_data = train_test_split(graph, test_size=0.1, random_state=0)\n",
    "train_data, val_data = train_test_split(train_val, test_size=0.2, random_state=0)\n",
    "\n",
    "val_data = torch.LongTensor(val_data)\n",
    "test_data = torch.LongTensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test graph:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathleensucipto/OneDrive/Harvard/1_Spring2020/HST956/project/COVID19-Drug-Repurposing/model/utils.py:201: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  norm = 1.0 / in_deg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 37908, # edges: 1745456\n"
     ]
    }
   ],
   "source": [
    "test_graph, test_rel, test_norm = utils.build_test_graph(\n",
    "        num_nodes, num_rels, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_deg = test_graph.in_degrees(\n",
    "                range(test_graph.number_of_nodes())).float().view(-1, 1)\n",
    "test_node_id = torch.arange(0, num_nodes, dtype=torch.long).view(-1, 1)\n",
    "test_rel = torch.from_numpy(test_rel)\n",
    "test_norm = node_norm_to_edge_norm(test_graph, torch.from_numpy(test_norm).view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example parameters:\n",
    "```\n",
    "args = {'dropout': 0.2,\n",
    "        'n_hidden': 5,\n",
    "        'gpu': 1,\n",
    "        'lr': 1e-2,\n",
    "        'n_bases': 100,\n",
    "        'n_layers': 2,\n",
    "        'n_epochs': 10,\n",
    "        'dataset': 'FB15k-237',\n",
    "        'eval_batch_size': 500,\n",
    "        'regularization': 0.01,\n",
    "        'grad_norm': 1.0,\n",
    "        'graph_batch_size': 3000,\n",
    "        'graph_split_size': 0.5,\n",
    "        'negative_sample': 10,\n",
    "        'evaluate_every': 10}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "model_param = {\n",
    "    'in_dim'   : num_nodes,\n",
    "    'h_dim'    : 100, # output feature size\n",
    "    'num_rels' : num_rels,\n",
    "    'dropout'  : 0.2,\n",
    "    'use_cuda' : False,\n",
    "    'reg_param': 0.01\n",
    "}\n",
    "use_cuda = model_param['use_cuda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = LinkPredict(in_dim   = model_param['in_dim'],\n",
    "                    h_dim    = model_param['h_dim'],\n",
    "                    num_rels = model_param['num_rels'],\n",
    "                    dropout  = model_param['dropout'],\n",
    "                    use_cuda = model_param['use_cuda'],\n",
    "                    reg_param= model_param['reg_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build adj list and calculate degrees for sampling\n",
    "adj_list, degrees = utils.get_adj_and_degrees(num_nodes, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "epoch_mult_eval = 5 # multiplication of n epochs to indicate when to evaluate\n",
    "best_mrr = 0\n",
    "forward_time = []\n",
    "backward_time = []\n",
    "eval_batch = 500\n",
    "model_state_file = 'model_state.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_graph_param = {\n",
    "    'sample_size'  : 30000, # edges to sample\n",
    "    'split_size'   : 0.5,\n",
    "    'negative_rate': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "# sampled nodes: 8305\n",
      "# sampled edges: 10000\n",
      "# nodes: 8305, # edges: 10000\n",
      "Finished edge sampling\n",
      "Epoch 0003 | Loss 1.9860 | Best MRR 0.0000 | Forward 0.5120s | Backward 0.5459s\n",
      "# sampled nodes: 8306\n",
      "# sampled edges: 10000\n",
      "# nodes: 8306, # edges: 10000\n",
      "Finished edge sampling\n",
      "Epoch 0004 | Loss 1.9709 | Best MRR 0.0000 | Forward 0.4758s | Backward 0.4646s\n",
      "# sampled nodes: 8377\n",
      "# sampled edges: 10000\n",
      "# nodes: 8377, # edges: 10000\n",
      "Finished edge sampling\n",
      "Epoch 0005 | Loss 2.0017 | Best MRR 0.0000 | Forward 0.4909s | Backward 0.4579s\n",
      "Run evaluation...\n"
     ]
    }
   ],
   "source": [
    "print(\"start training...\")\n",
    "while True:\n",
    "    model.train()\n",
    "    epoch += 1\n",
    "\n",
    "    # Perform edge neighborhood sampling to generate training graph and data\n",
    "    # The training stage is performed on a sample graph (not the entire graph)\n",
    "    g, node_id, edge_type, node_norm, data, labels = \\\n",
    "        utils.generate_sampled_graph_and_labels(\n",
    "            train_data, \n",
    "            sample_graph_param['sample_size'],\n",
    "            sample_graph_param['split_size'],\n",
    "            num_rels, \n",
    "            adj_list,\n",
    "            degrees,\n",
    "            sample_graph_param['negative_rate'])\n",
    "    \n",
    "    print(\"Finished edge sampling\")\n",
    "    \n",
    "    # set node/edge feature\n",
    "    node_id = torch.from_numpy(node_id).view(-1, 1).long()\n",
    "    edge_type = torch.from_numpy(edge_type)\n",
    "    edge_norm = node_norm_to_edge_norm(g, torch.from_numpy(node_norm).view(-1, 1))\n",
    "    data, labels = torch.from_numpy(data), torch.from_numpy(labels)\n",
    "    deg = g.in_degrees(range(g.number_of_nodes())).float().view(-1, 1)\n",
    "    if use_cuda:\n",
    "        node_id, deg = node_id.cuda(), deg.cuda()\n",
    "        edge_type, edge_norm = edge_type.cuda(), edge_norm.cuda()\n",
    "        data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    t0 = time.time()\n",
    "    embed = model(g, node_id, edge_type, edge_norm)\n",
    "    loss = model.get_loss(g, embed, data, labels)\n",
    "    t1 = time.time()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients\n",
    "    optimizer.step()\n",
    "    t2 = time.time()\n",
    "\n",
    "    forward_time.append(t1 - t0)\n",
    "    backward_time.append(t2 - t1)\n",
    "    print(\"Epoch {:04d} | Loss {:.4f} | Best MRR {:.4f} | Forward {:.4f}s | Backward {:.4f}s\".\n",
    "              format(epoch, loss.item(), best_mrr, forward_time[-1], backward_time[-1]))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # validation\n",
    "    if epoch % epoch_mult_eval == 0:\n",
    "        print('Run evaluation...')\n",
    "        # perform validation on CPU because full graph is too large\n",
    "        if use_cuda: model.cpu()\n",
    "        model.eval()\n",
    "        embed = model(test_graph, test_node_id, test_rel, test_norm)\n",
    "        mrr = utils.calc_mrr(embed, model.w_relation, torch.LongTensor(train_data),\n",
    "                             val_data, test_data, hits=[1, 3, 10], eval_bz=eval_batch,\n",
    "                             eval_p='filtered')\n",
    "        # save best model\n",
    "        if mrr < best_mrr:\n",
    "            if epoch >= 20:\n",
    "                break\n",
    "        else:\n",
    "            best_mrr = mrr\n",
    "            torch.save({'state_dict': model.state_dict(), 'epoch': epoch},\n",
    "                       model_state_file)\n",
    "        if use_cuda:\n",
    "            model.cuda()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
